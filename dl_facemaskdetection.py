# -*- coding: utf-8 -*-
"""DL_FaceMaskDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1No_yuaO8qR-nzRJxLYUyneHKXAv38MdG
"""

!pip install kaggle

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

#API to fetch the dataset from kaggle

!kaggle datasets download -d omkargurav/face-mask-dataset



from zipfile import ZipFile
dataset = '/content/face-mask-dataset.zip'

with ZipFile(dataset, 'r') as zip:
  zip.extractall()
  print('Extracted')

!ls

"""**Importing the dependencies**"""

import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2
from google.colab.patches import cv2_imshow
from PIL import Image
from sklearn.model_selection import train_test_split

with_mask_files = os.listdir('/content/data/with_mask')
print(with_mask_files[0:5])

without_mask_files = os.listdir('/content/data/without_mask')
print(without_mask_files[0:5])

print('number of mask', len(with_mask_files))
print('number of without_mask', len(without_mask_files))

"""**Creating labels for the two class of images**

**with mask** --> 1
**without mask **--> 0
"""



"""create labels
### Label encoding
"""

with_mask_labels = [1]*3725
without_mask_labels = [0]*3828

print(len(with_mask_labels))
print(len(without_mask_labels))

labels = with_mask_labels + without_mask_labels

print(len(labels))

print(labels[0:5])

"""**Displaying the images**"""

# displaying with mask image
img = mpimg.imread('/content/data/with_mask/with_mask_1.jpg')
imgplot = plt.imshow(img)
plt.show()

# displaying with mask image
img = mpimg.imread('/content/data/without_mask/without_mask_1.jpg')
imgplot = plt.imshow(img)
plt.show()

with_mask_path = '/content/data/with_mask/'

data = []

for img_file in with_mask_files:

  image = Image.open(with_mask_path + img_file)
  image = image.resize((128,128))
  image = image.convert('RGB')
  image = np.array(image)
  data.append(image)

without_mask_path = '/content/data/without_mask/'

for img_file in without_mask_files:

  image = Image.open(without_mask_path + img_file)
  image = image.resize((128,128))
  image = image.convert('RGB')
  image = np.array(image)
  data.append(image)

type(data)

len(data)

type(data[0])

data[0].shape

X = np.array(data)
Y = np.array(labels)

type(X)

print(X.shape)
  print(Y.shape)

"""**Train Test split**"""

X_train,X_test,Y_train,Y_test =train_test_split(X,Y,test_size=0.2,random_state=2)

print(X.shape,X_train.shape,X_test.shape)

# Scaling the data

X_train_scaled = X_train/255
X_test_scaled = X_test/255

X_train_scaled[0]

"""**Building neural network**"""

import tensorflow as tf
from tensorflow import keras

num_of_classes = 2

model = keras.Sequential() #stack layers

#add layers
model.add(keras.layers.Conv2D(32,kernel_size = (3,3),activation='relu',input_shape=(128,128,3)))
model.add(keras.layers.MaxPooling2D(pool_size = (2,2)))

model.add(keras.layers.Conv2D(64,kernel_size = (3,3),activation='relu'))
model.add(keras.layers.MaxPooling2D(pool_size = (2,2)))

# Flatten converts arrays to vectors
model.add(keras.layers.Flatten())

model.add(keras.layers.Dense(128,activation = 'relu'))
model.add(keras.layers.Dropout(0.5))

          # Dense layer connects neurons of current layers to previous layers
model.add(keras.layers.Dense(64,activation = 'relu'))
model.add(keras.layers.Dropout(0.5))

          # sigmoid = for binary classes, softmax = for multiple classes
model.add(keras.layers.Dense(num_of_classes,activation = 'sigmoid'))

#Compiling the neural network
model.compile(optimizer = 'adam',
              loss = 'sparse_categorical_crossentropy',
              metrics = ['acc'])

history = model.fit(X_train_scaled, Y_train, validation_split=0.1,epochs = 5)
#less epoch as we have small dataset to avoid overfitting

"""**Model Accuracy**"""

loss,accuracy = model.evaluate(X_test_scaled,Y_test)
print('Test accuracy', accuracy)

input_image_path = input('Kindly give the path of the image')
input_image = cv2.imread(input_image_path)

cv2_imshow(input_image)

input_image_resized = cv2.resize(input_image, (128,128))

input_image_scaled = input_image_resized/255

input_image_reshaped = np.reshape(input_image_scaled,[1,128,128,3])

input_prediction = model.predict(input_image_reshaped)

print(input_prediction)

input_pred_model = np.argmax(input_prediction)

print(input_pred_model)

if input_pred_model == 1:
  print('Person is wearing a mask')
else:
  print('Person is not wearing a mask')

